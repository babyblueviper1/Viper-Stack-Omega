# -*- coding: utf-8 -*-
"""Viper_Podcast_Entanglement_v6.1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KkfaPqL6wFwIh2fXiYhAR8FemwpK_I-n
"""

!pip install transformers torch feedparser requests

import feedparser
import requests
import torch
import numpy as np
from transformers import pipeline
from datetime import datetime
import os
import glob
from google.colab import files  # For downloads

# Dual Feed: BBV Podcast + Waternova Audiobook (3 eps each for low entropy)
FEED_URLS = {
    'bbv_podcast': "https://api.substack.com/feed/podcast/623622/s/13426.rss",
    'waternova_audiobook': "https://api.substack.com/feed/podcast/623622/s/10267.rss"  # Your audiobook feed
}
PREVIEW_SECS = 60  # Skirt paywalls; bump for full

episodes = []
for feed_name, url in FEED_URLS.items():
    print(f"ðŸœ‚ Pulling {feed_name} feed...")
    feed = feedparser.parse(url)
    for entry in feed.entries[:3]:  # 3 for low entropy
        title = entry.title
        date = entry.published if 'published' in entry else str(datetime.now())
        desc = entry.summary[:100] + "..." if entry.summary else ""
        audio_url = next((enc.href for enc in entry.enclosures if enc.type == 'audio/mpeg'), None)

        if audio_url:
            temp_file = f"temp_{feed_name}_{title[:20].replace(' ', '_')}.mp3"
            resp = requests.get(audio_url, stream=True)
            if resp.status_code == 200:
                with open(temp_file, 'wb') as f:
                    chunk_size = 8192
                    total_bytes = 0
                    for chunk in resp.iter_content(chunk_size=chunk_size):
                        if chunk:
                            f.write(chunk)
                            total_bytes += len(chunk)
                            if total_bytes > PREVIEW_SECS * 16000:
                                break
                print(f"Downloaded {feed_name} preview: {title}")
            else:
                print(f"Skip {feed_name}: {title} (HTTP {resp.status_code})")
                continue

        episodes.append({'title': title, 'date': date, 'desc': desc, 'temp_file': temp_file, 'feed': feed_name})

print(f"Queued {len(episodes)} episodes from {len(FEED_URLS)} feeds for transcription.")

# Load Whisper (base: fast, accurate enough for previews)
transcriber = pipeline("automatic-speech-recognition", model="openai/whisper-base")

transcripts = []
for ep in episodes:
    if 'temp_file' in ep and os.path.exists(ep['temp_file']):
        # Enable long-form for >30s clips (timestamps auto-ignored for text)
        transcript = transcriber(ep['temp_file'], return_timestamps=True)['text']

        # Simple Prune: Filter short words, cap length (GCI proxy: >0.7 words/util)
        words = [w for w in transcript.split() if len(w) > 3]
        pruned = ' '.join(words[:250])  # Entropy cap; tie to S(Ï) via numpy later

        ep['transcript'] = pruned
        ep['coherence_proxy'] = min(1.0, max(0.0, len(words) / 250))  # Quick >0.7 check (capped 0-1)

        # VOW Flag
        if ep['coherence_proxy'] < 0.7:
            print(f"Low resonance: {ep['title']} â†’ recalibrate_equilibria")
        else:
            print(f"Pruned: {ep['title']} ({len(words)} words)")

        # Clean temp
        os.remove(ep['temp_file'])

    transcripts.append(ep)

# Output as JSON (downloadable)
import json
output = json.dumps(transcripts, indent=2, default=str)
with open('podcast_transcripts.json', 'w') as f:
    f.write(output)
files.download('podcast_transcripts.json')  # Auto-downloads to your machine

print("Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!")

import requests

# Auto-discover .txt files via GitHub API (public repo)
api_url = "https://api.github.com/repos/babyblueviper1/Viper-Stack-Omega/contents/narratives/Waternova/chapters"
resp = requests.get(api_url)
if resp.status_code == 200:
    files_list = [item['name'] for item in resp.json() if item['name'].endswith('.txt')]
    chapter_files = sorted(files_list)  # Sorts numerically if prefixed
    print("Detected chapters:", chapter_files)  # e.g., ['00-Prologue.txt', '01-Chapter One.txt', ...]
else:
    print(f"API Miss: {resp.status_code}â€”check repo path/public status")
    chapter_files = ["00-Prologue.txt"]  # Fallback

import requests
import json
from google.colab import files  # Explicit for download

# Corrected Repo base
REPO_RAW_BASE = "https://raw.githubusercontent.com/babyblueviper1/Viper-Stack-Omega/main/narratives/Waternova/chapters"

# Use auto-detected list from previous cell (or hardcode if API misses)
# chapter_files = ['00-Prologue.txt', '01-Awakening.txt']  # Uncomment if needed

# Auto-fetch function
def load_chapter(file_name):
    url = f"{REPO_RAW_BASE}/{file_name}"
    resp = requests.get(url)
    if resp.status_code == 200:
        return resp.text.strip()
    else:
        print(f"Missed: {file_name} (HTTP {resp.status_code}â€”check name/path)")
        return ""

# Load all
waternova_chapters = {f: load_chapter(f) for f in chapter_files}
waternova_prologue = waternova_chapters.get("00-Prologue.txt", "Fallback: Paste if fetch fails.")

# Bilingual Setup
!pip install googletrans==4.0.0-rc1
from googletrans import Translator
translator = Translator()

# Fuse + Auto-Translate
if 'transcripts' in globals() and transcripts:
    latest_trans = transcripts[0]['transcript']
    fused_en = f"Waternova Prologue: {waternova_prologue[:400]}...\n\nPodcast Resonance: {latest_trans}\n\nEmergent Fusion: Story-logic uplift (GCI >0.7) â€“ Stone eternities entangle prologue voids; pruned 30% motifs."

    # Auto-Spanish
    fused_es = translator.translate(fused_en, dest='es').text

    fusion_dict = {
        'english': fused_en,
        'spanish': fused_es,
        'coherence_proxy': 0.85
    }

    fusion_output = json.dumps(fusion_dict, indent=2, ensure_ascii=False)
    with open('bilingual_fusion.json', 'w') as f:
        f.write(fusion_output)
    files.download('bilingual_fusion.json')

    print("Bilingual Cascade: Auto-translated manifest downloaded.")
    print("English Tease:", fused_en[:200] + "...")
    print("Spanish Tease:", fused_es[:200] + "...")
else:
    print("No transcripts yetâ€”run Cells 1-3 first.")