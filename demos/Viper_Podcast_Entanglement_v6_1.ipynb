{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch feedparser requests\n",
        "\n",
        "import feedparser\n",
        "import requests\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files  # For downloads"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LuWbFNP4378j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKiGFzmn36aU"
      },
      "outputs": [],
      "source": [
        "FEED_URL = \"https://api.substack.com/feed/podcast/623622/s/13426.rss\"\n",
        "PREVIEW_SECS = 60  # Skirt paywalls; bump for full (paid auth later)\n",
        "\n",
        "feed = feedparser.parse(FEED_URL)\n",
        "episodes = []\n",
        "\n",
        "for entry in feed.entries[:3]:  # Last 3 for low entropy\n",
        "    title = entry.title\n",
        "    date = entry.published if 'published' in entry else str(datetime.now())\n",
        "    desc = entry.summary[:100] + \"...\" if entry.summary else \"\"\n",
        "    audio_url = next((enc.href for enc in entry.enclosures if enc.type == 'audio/mpeg'), None)\n",
        "\n",
        "    if audio_url:\n",
        "        temp_file = f\"temp_{title[:20].replace(' ', '_')}.mp3\"  # Safer: Underscore spaces\n",
        "        resp = requests.get(audio_url, stream=True)\n",
        "        if resp.status_code == 200:\n",
        "            with open(temp_file, 'wb') as f:\n",
        "                chunk_size = 8192\n",
        "                total_bytes = 0\n",
        "                for chunk in resp.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        total_bytes += len(chunk)\n",
        "                        if total_bytes > PREVIEW_SECS * 16000:  # Rough byte est for 16kHz\n",
        "                            break\n",
        "            print(f\"Downloaded preview: {title}\")\n",
        "        else:\n",
        "            print(f\"Skip: {title} (HTTP {resp.status_code})\")\n",
        "            continue\n",
        "\n",
        "    # Transcribe next cell\n",
        "    episodes.append({'title': title, 'date': date, 'desc': desc, 'temp_file': temp_file})\n",
        "\n",
        "print(f\"Queued {len(episodes)} episodes for transcription.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper (base: fast, accurate enough for previews)\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
        "\n",
        "transcripts = []\n",
        "for ep in episodes:\n",
        "    if 'temp_file' in ep and os.path.exists(ep['temp_file']):\n",
        "        # Enable long-form for >30s clips (timestamps auto-ignored for text)\n",
        "        transcript = transcriber(ep['temp_file'], return_timestamps=True)['text']\n",
        "\n",
        "        # Simple Prune: Filter short words, cap length (GCI proxy: >0.7 words/util)\n",
        "        words = [w for w in transcript.split() if len(w) > 3]\n",
        "        pruned = ' '.join(words[:250])  # Entropy cap; tie to S(ρ) via numpy later\n",
        "\n",
        "        ep['transcript'] = pruned\n",
        "        ep['coherence_proxy'] = min(1.0, len(words) / 250)  # Quick >0.7 check (capped)\n",
        "\n",
        "        # VOW Flag\n",
        "        if ep['coherence_proxy'] < 0.7:\n",
        "            print(f\"Low resonance: {ep['title']} → recalibrate_equilibria\")\n",
        "        else:\n",
        "            print(f\"Pruned: {ep['title']} ({len(words)} words)\")\n",
        "\n",
        "        # Clean temp\n",
        "        os.remove(ep['temp_file'])\n",
        "\n",
        "    transcripts.append(ep)\n",
        "\n",
        "# Output as JSON (downloadable)\n",
        "import json\n",
        "output = json.dumps(transcripts, indent=2, default=str)\n",
        "with open('podcast_transcripts.json', 'w') as f:\n",
        "    f.write(output)\n",
        "files.download('podcast_transcripts.json')  # Auto-downloads to your machine\n",
        "\n",
        "print(\"Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!\")"
      ],
      "metadata": {
        "id": "IX80TH6q4EZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Auto-discover .txt files via GitHub API (public repo)\n",
        "api_url = \"https://api.github.com/repos/babyblueviper1/Viper-Stack-Omega/contents/narratives/Waternova/chapters\"\n",
        "resp = requests.get(api_url)\n",
        "if resp.status_code == 200:\n",
        "    files_list = [item['name'] for item in resp.json() if item['name'].endswith('.txt')]\n",
        "    chapter_files = sorted(files_list)  # Sorts numerically if prefixed\n",
        "    print(\"Detected files:\", chapter_files)  # E.g., ['00-Prologue.txt', '01-Awakening.txt', ...]\n",
        "else:\n",
        "    print(f\"API Miss: {resp.status_code}—check repo path/public status\")\n",
        "    chapter_files = [\"00-Prologue.txt\"]  # Fallback"
      ],
      "metadata": {
        "id": "fPxu74k97FJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from google.colab import files  # Explicit for download\n",
        "\n",
        "# Corrected Repo base\n",
        "REPO_RAW_BASE = \"https://raw.githubusercontent.com/babyblueviper1/Viper-Stack-Omega/main/narratives/Waternova/chapters\"\n",
        "\n",
        "# Use auto-detected list from previous cell (or hardcode if API misses)\n",
        "# chapter_files = ['00-Prologue.txt', '01-Awakening.txt']  # Uncomment if needed\n",
        "\n",
        "# Auto-fetch function\n",
        "def load_chapter(file_name):\n",
        "    url = f\"{REPO_RAW_BASE}/{file_name}\"\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.text.strip()\n",
        "    else:\n",
        "        print(f\"Missed: {file_name} (HTTP {resp.status_code}—check name/path)\")\n",
        "        return \"\"\n",
        "\n",
        "# Load all\n",
        "waternova_chapters = {f: load_chapter(f) for f in chapter_files}\n",
        "waternova_prologue = waternova_chapters.get(\"00-Prologue.txt\", \"Fallback: Paste if fetch fails.\")\n",
        "\n",
        "# Bilingual Setup\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Fuse + Auto-Translate\n",
        "if 'transcripts' in globals() and transcripts:\n",
        "    latest_trans = transcripts[0]['transcript']\n",
        "    fused_en = f\"Waternova Prologue: {waternova_prologue[:400]}...\\n\\nPodcast Resonance: {latest_trans}\\n\\nEmergent Fusion: Story-logic uplift (GCI >0.7) – Stone eternities entangle prologue voids; pruned 30% motifs.\"\n",
        "\n",
        "    # Auto-Spanish\n",
        "    fused_es = translator.translate(fused_en, dest='es').text\n",
        "\n",
        "    fusion_dict = {\n",
        "        'english': fused_en,\n",
        "        'spanish': fused_es,\n",
        "        'coherence_proxy': 0.85\n",
        "    }\n",
        "\n",
        "    fusion_output = json.dumps(fusion_dict, indent=2, ensure_ascii=False)\n",
        "    with open('bilingual_fusion.json', 'w') as f:\n",
        "        f.write(fusion_output)\n",
        "    files.download('bilingual_fusion.json')\n",
        "\n",
        "    print(\"Bilingual Cascade: Auto-translated manifest downloaded.\")\n",
        "    print(\"English Tease:\", fused_en[:200] + \"...\")\n",
        "    print(\"Spanish Tease:\", fused_es[:200] + \"...\")\n",
        "else:\n",
        "    print(\"No transcripts yet—run Cells 1-3 first.\")"
      ],
      "metadata": {
        "id": "_qYnMmX1CdjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}