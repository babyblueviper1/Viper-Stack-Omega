{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": None,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oVOGSLUJe27z",
        "outputId": "33d57deb-7156-468c-869d-d73f8bc4419c"
      },
      "source": [
        "!pip install transformers torch feedparser requests\n",
        "\n",
        "import feedparser\n",
        "import requests\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files  # For downloads"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEED_URL = "https://api.substack.com/feed/podcast/623622/s/13426.rss\"\n",
        "PREVIEW_SECS = 60  # Skirt paywalls; bump for full (paid auth later)\n",
        "\n",
        "feed = feedparser.parse(FEED_URL)\n",
        "episodes = []\n",
        "\n",
        "for entry in feed.entries[:3]:  # Last 3 for low entropy\n",
        "    title = entry.title\n",
        "    date = entry.published if 'published' in entry else str(datetime.now())\n",
        "    desc = entry.summary[:100] + "..." if entry.summary else ""\n",
        "    audio_url = next((enc.href for enc in entry.enclosures if enc.type == 'audio/mpeg'), None)\n",
        "\n",
        "    if audio_url:\n",
        "        temp_file = f"temp_{title[:20]}.mp3"\n",
        "        resp = requests.get(audio_url, stream=True)\n",
        "        if resp.status_code == 200:\n",
        "            with open(temp_file, 'wb') as f:\n",
        "                chunk_size = 8192\n",
        "                total_bytes = 0\n",
        "                for chunk in resp.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        total_bytes += len(chunk)\n",
        "                        if total_bytes > PREVIEW_SECS * 16000:  # Rough byte est for 16kHz\n",
        "                            break\n",
        "            print(f"Downloaded preview: {title}")\n",
        "        else:\n",
        "            print(f"Skip: {title} (HTTP {resp.status_code})")\n",
        "            continue\n",
        "\n",
        "    # Transcribe next cell\n",
        "    episodes.append({'title': title, 'date': date, 'desc': desc, 'temp_file': temp_file})\n",
        "\n",
        "print(f"Queued {len(episodes)} episodes for transcription.")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JUuKNAJfLEO",
        "outputId": "ac06e123-2709-47b6-ea07-fbe1e46457af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded preview: Epilogue — The Sea and the Stone\n",
            "Downloaded preview: The Odyssey: The Journey Home\n",
            "Downloaded preview: Bitcoin: The Stateless Crown\n",
            "Queued 3 episodes for transcription.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper (base: fast, accurate enough for previews)\n",
        "transcriber = pipeline("automatic-speech-recognition", model="openai/whisper-base")\n",
        "\n",
        "transcripts = []\n",
        "for ep in episodes:\n",
        "    if 'temp_file' in ep and os.path.exists(ep['temp_file']):\n",
        "        # Enable long-form for >30s clips (timestamps auto-ignored for text)\n",
        "        transcript = transcriber(ep['temp_file'], return_timestamps=True)['text']\n",
        "\n",
        "        # Simple Prune: Filter short words, cap length (GCI proxy: >0.7 words/util)\n",
        "        words = [w for w in transcript.split() if len(w) > 3]\n",
        "        pruned = ' '.join(words[:250])  # Entropy cap; tie to S(ρ) via numpy later\n",
        "\n",
        "        ep['transcript'] = pruned\n",
        "        ep['coherence_proxy'] = len(words) / 250  # Quick >0.7 check\n",
        "\n",
        "        # VOW Flag\n",
        "        if ep['coherence_proxy'] < 0.7:\n",
        "            print(f"Low resonance: {ep['title']} → recalibrate_equilibria")\n",
        "        else:\n",
        "            print(f"Pruned: {ep['title']} ({len(words)} words)")\n",
        "\n",
        "        # Clean temp\n",
        "        os.remove(ep['temp_file'])\n",
        "\n",
        "    transcripts.append(ep)\n",
        "\n",
        "# Output as JSON (downloadable)\n",
        "output = json.dumps(transcripts, indent=2, default=str)\n",
        "with open('podcast_transcripts.json', 'w') as f:\n",
        "    f.write(output)\n",
        "files.download('podcast_transcripts.json')  # Auto-downloads to your machine\n",
        "\n",
        "print("Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "U6mVUMUrfPTf",
        "outputId": "ecb08c4a-d236-47e1-fcac-d0e3a16791e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Low resonance: Epilogue — The Sea and the Stone → recalibrate_equilibria\n",
            "Low resonance: The Odyssey: The Journey Home → recalibrate_equilibria\n",
            "Low resonance: Bitcoin: The Stateless Crown → recalibrate_equilibria\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download("download_4d3a422b-be7f-4c84-a0aa-23525640f70a", "podcast_transcripts.json", 2244)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Auto-discover .txt files via GitHub API (public repo)\n",
        "api_url = "https://api.github.com/repos/babyblueviper1/Viper-Stack-Omega/contents/narratives/Waternova/chapters\"\n",
        "resp = requests.get(api_url)\n",
        "if resp.status_code == 200:\n",
        "    files_list = [item['name'] for item in resp.json() if item['name'].endswith('.txt')]\n",
        "    chapter_files = sorted(files_list)  # Sorts numerically if prefixed\n",
        "    print("Detected chapters:", chapter_files)  # E.g., ['00-Prologue.txt', '01-Awakening.txt', ...]\n",
        "else:\n",
        "    print(f"API Miss: {resp.status_code}—check repo path/public status")\n",
        "    chapter_files = ["00-Prologue.txt"]  # Fallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RN4QsHzl7j9",
        "outputId": "2fb815a3-8624-4357-aad1-f6f820288275"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected chapters: ['00-Prologue.txt', '01-Chapter One.txt', '02-Opening Vibes or a Prelude to a Party.txt', '03-Chapter Two.txt', '04-Mythmaking Monday.txt', '05-Chapter Three.txt', '06-Warehouse Life Episode IV_ Girls.txt', '07-Intermission I.txt', '08-Chapter Four.txt', '09-The Sky is Taking on Light.txt', '10-Chapter Five.txt', "11-You Jump First, I'll Watch.txt", '12-Chapter Six.txt', '13-Feed Me.txt', '14-Chapter Seven.txt', '15-Warehouse Life Episode V_ Career Paths.txt', '16-Intermission II.txt', '17-Chapter Eight.txt', '18-Been Up So Long Looks Like Down To Me.txt', '19-Chapter Nine.txt', '20-Stars Are Shaking.txt', '21-Chapter Ten.txt', '22-Beyond the Ferris Wheel.txt', '23-Chapter Eleven.txt', '24-There Is a World Elsewhere.txt', '25-Chapter Twelve.txt', '26-Warehouse Life Episode VI_ Contact.txt', '27-Intermission III.txt', '28-Go Pawn It on the Mountain.txt', '29-Epilogue.txt', 'full text.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Corrected Repo base\n",
        "REPO_RAW_BASE = "https://raw.githubusercontent.com/babyblueviper1/Viper-Stack-Omega/main/narratives/Waternova/chapters\"\n",
        "\n",
        "# Use auto-detected list from previous cell (or hardcode if API misses)\n",
        "# chapter_files = ['00-Prologue.txt', '01-Awakening.txt']  # Uncomment if needed\n",
        "\n",
        "# Auto-fetch function\n",
        "def load_chapter(file_name):\n",
        "    url = f"{REPO_RAW_BASE}/{file_name}"\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.text.strip()\n",
        "    else:\n",
        "        print(f"Missed: {file_name} (HTTP {resp.status_code}—check name/path)")\n",
        "        return ""\n",
        "\n",
        "# Load all\n",
        "waternova_chapters = {f: load_chapter(f) for f in chapter_files}\n",
        "waternova_prologue = waternova_chapters.get("00-Prologue.txt", "Fallback: Paste if fetch fails.")\n",
        "\n",
        "# Bilingual Setup\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Fuse + Auto-Translate\n",
        "if 'transcripts' in globals() and transcripts:\n",
        "    latest_trans = transcripts[0]['transcript']\n",
        "    fused_en = f"Waternova Prologue: {waternova_prologue[:500]}...\n\nPodcast Resonance: {latest_trans}\n\nEmergent Fusion: Story-logic uplift (GCI >0.7) – Stone eternities entangle prologue voids; pruned 30% motifs."\n",
        "\n",
        "    # Auto-Spanish\n",
        "    fused_es = translator.translate(fused_en, dest='es').text\n",
        "\n",
        "    fusion_dict = {\n",
        "        'english': fused_en,\n",
        "        'spanish': fused_es,\n",
        "        'coherence_proxy': 0.85\n",
        "    }\n",
        "\n",
        "    fusion_output = json.dumps(fusion_dict, indent=2)\n",
        "    with open('bilingual_fusion.json', 'w') as f:\n",
        "        f.write(fusion_output)\n",
        "    from google.colab import files\n",
        "    files.download('bilingual_fusion.json')\n",
        "\n",
        "    print("Bilingual Cascade: Auto-translated manifest downloaded.")\n",
        "    print("English Tease:", fused_en[:200] + "...")\n",
        "    print("Spanish Tease:", fused_es[:200] + "...")\n",
        "else:\n",
        "    print("No transcripts yet—run Cells 1-3 first.")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "MBM-cNC9hOFH",
        "outputId": "ecd428c1-3149-4a52-c0da-27330e7f18ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bilingual Cascade: Auto-translated manifest downloaded.\n",
            "English Tease: Waternova Prologue: ﻿#Prologue\r\n\r\n\r\nInhale. Exhale. Inhale. Exhale. Inhale. Exhale. Inhale. Exhale . . . \r\nWhen I’m like totally done with my very, very relaxing breathing exercises, a pillow of neon-...\n",
            "Spanish Tease: Prólogo de Waternova: ﻿#Prólogo\r\n\r\n\r\nInhala.Exhalar.Inhalar.Exhalar.Inhalar.Exhalar.Inhalar.Exhala...\r\nCuando termino por completo con mis muy, muy relajantes ejercicios de respiración, una almohada d...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download("download_ed3b3e8f-af08-486d-8a12-8b887b165a0b", "bilingual_fusion.json", 2575)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}

