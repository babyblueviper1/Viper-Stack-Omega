{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oVOGSLUJe27z",
        "outputId": "33d57deb-7156-468c-869d-d73f8bc4419c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.12/dist-packages (6.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch feedparser requests\n",
        "\n",
        "import feedparser\n",
        "import requests\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files  # For downloads"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEED_URL = \"https://api.substack.com/feed/podcast/623622/s/13426.rss\"\n",
        "PREVIEW_SECS = 60  # Skirt paywalls; bump for full (paid auth later)\n",
        "\n",
        "feed = feedparser.parse(FEED_URL)\n",
        "episodes = []\n",
        "\n",
        "for entry in feed.entries[:3]:  # Last 3 for low entropy\n",
        "    title = entry.title\n",
        "    date = entry.published if 'published' in entry else str(datetime.now())\n",
        "    desc = entry.summary[:100] + \"...\" if entry.summary else \"\"\n",
        "    audio_url = next((enc.href for enc in entry.enclosures if enc.type == 'audio/mpeg'), None)\n",
        "\n",
        "    if audio_url:\n",
        "        temp_file = f\"temp_{title[:20]}.mp3\"\n",
        "        resp = requests.get(audio_url, stream=True)\n",
        "        if resp.status_code == 200:\n",
        "            with open(temp_file, 'wb') as f:\n",
        "                chunk_size = 8192\n",
        "                total_bytes = 0\n",
        "                for chunk in resp.iter_content(chunk_size=chunk_size):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        total_bytes += len(chunk)\n",
        "                        if total_bytes > PREVIEW_SECS * 16000:  # Rough byte est for 16kHz\n",
        "                            break\n",
        "            print(f\"Downloaded preview: {title}\")\n",
        "        else:\n",
        "            print(f\"Skip: {title} (HTTP {resp.status_code})\")\n",
        "            continue\n",
        "\n",
        "    # Transcribe next cell\n",
        "    episodes.append({'title': title, 'date': date, 'desc': desc, 'temp_file': temp_file})\n",
        "\n",
        "print(f\"Queued {len(episodes)} episodes for transcription.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JUuKNAJfLEO",
        "outputId": "ac06e123-2709-47b6-ea07-fbe1e46457af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded preview: Epilogue — The Sea and the Stone\n",
            "Downloaded preview: The Odyssey: The Journey Home\n",
            "Downloaded preview: Bitcoin: The Stateless Crown\n",
            "Queued 3 episodes for transcription.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper (base: fast, accurate enough for previews)\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
        "\n",
        "transcripts = []\n",
        "for ep in episodes:\n",
        "    if 'temp_file' in ep and os.path.exists(ep['temp_file']):\n",
        "        # Enable long-form for >30s clips (timestamps auto-ignored for text)\n",
        "        transcript = transcriber(ep['temp_file'], return_timestamps=True)['text']\n",
        "\n",
        "        # Simple Prune: Filter short words, cap length (GCI proxy: >0.7 words/util)\n",
        "        words = [w for w in transcript.split() if len(w) > 3]\n",
        "        pruned = ' '.join(words[:250])  # Entropy cap; tie to S(ρ) via numpy later\n",
        "\n",
        "        ep['transcript'] = pruned\n",
        "        ep['coherence_proxy'] = len(words) / 250  # Quick >0.7 check\n",
        "\n",
        "        # VOW Flag\n",
        "        if ep['coherence_proxy'] < 0.7:\n",
        "            print(f\"Low resonance: {ep['title']} → recalibrate_equilibria\")\n",
        "        else:\n",
        "            print(f\"Pruned: {ep['title']} ({len(words)} words)\")\n",
        "\n",
        "        # Clean temp\n",
        "        os.remove(ep['temp_file'])\n",
        "\n",
        "    transcripts.append(ep)\n",
        "\n",
        "# Output as JSON (downloadable)\n",
        "import json\n",
        "output = json.dumps(transcripts, indent=2, default=str)\n",
        "with open('podcast_transcripts.json', 'w') as f:\n",
        "    f.write(output)\n",
        "files.download('podcast_transcripts.json')  # Auto-downloads to your machine\n",
        "\n",
        "print(\"Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "U6mVUMUrfPTf",
        "outputId": "ecb08c4a-d236-47e1-fcac-d0e3a16791e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Low resonance: Epilogue — The Sea and the Stone → recalibrate_equilibria\n",
            "Low resonance: The Odyssey: The Journey Home → recalibrate_equilibria\n",
            "Low resonance: Bitcoin: The Stateless Crown → recalibrate_equilibria\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d3a422b-be7f-4c84-a0aa-23525640f70a\", \"podcast_transcripts.json\", 2244)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Auto-discover .txt files via GitHub API (public repo)\n",
        "api_url = \"https://api.github.com/repos/babyblueviper1/Viper-Stack-Omega/contents/narratives/Waternova/chapters\"\n",
        "resp = requests.get(api_url)\n",
        "if resp.status_code == 200:\n",
        "    files_list = [item['name'] for item in resp.json() if item['name'].endswith('.txt')]\n",
        "    chapter_files = sorted(files_list)  # Sorts numerically if prefixed\n",
        "    print(\"Detected chapters:\", chapter_files)  # E.g., ['00-Prologue.txt', '01-Awakening.txt', ...]\n",
        "else:\n",
        "    print(f\"API Miss: {resp.status_code}—check repo path/public status\")\n",
        "    chapter_files = [\"00-Prologue.txt\"]  # Fallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RN4QsHzl7j9",
        "outputId": "2fb815a3-8624-4357-aad1-f6f820288275"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected chapters: ['00-Prologue.txt', '01-Chapter One.txt', '02-Opening Vibes or a Prelude to a Party.txt', '03-Chapter Two.txt', '04-Mythmaking Monday.txt', '05-Chapter Three.txt', '06-Warehouse Life Episode IV_ Girls.txt', '07-Intermission I.txt', '08-Chapter Four.txt', '09-The Sky is Taking on Light.txt', '10-Chapter Five.txt', \"11-You Jump First, I'll Watch.txt\", '12-Chapter Six.txt', '13-Feed Me.txt', '14-Chapter Seven.txt', '15-Warehouse Life Episode V_ Career Paths.txt', '16-Intermission II.txt', '17-Chapter Eight.txt', '18-Been Up So Long Looks Like Down To Me.txt', '19-Chapter Nine.txt', '20-Stars Are Shaking.txt', '21-Chapter Ten.txt', '22-Beyond the Ferris Wheel.txt', '23-Chapter Eleven.txt', '24-There Is a World Elsewhere.txt', '25-Chapter Twelve.txt', '26-Warehouse Life Episode VI_ Contact.txt', '27-Intermission III.txt', '28-Go Pawn It on the Mountain.txt', '29-Epilogue.txt', 'full text.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Corrected Repo base\n",
        "REPO_RAW_BASE = \"https://raw.githubusercontent.com/babyblueviper1/Viper-Stack-Omega/main/narratives/Waternova/chapters\"\n",
        "\n",
        "# Use auto-detected list from previous cell (or hardcode if API misses)\n",
        "# chapter_files = ['00-Prologue.txt', '01-Awakening.txt']  # Uncomment if needed\n",
        "\n",
        "# Auto-fetch function\n",
        "def load_chapter(file_name):\n",
        "    url = f\"{REPO_RAW_BASE}/{file_name}\"\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.text.strip()\n",
        "    else:\n",
        "        print(f\"Missed: {file_name} (HTTP {resp.status_code}—check name/path)\")\n",
        "        return \"\"\n",
        "\n",
        "# Load all\n",
        "waternova_chapters = {f: load_chapter(f) for f in chapter_files}\n",
        "waternova_prologue = waternova_chapters.get(\"00-Prologue.txt\", \"Fallback: Paste if fetch fails.\")\n",
        "\n",
        "# Bilingual Setup\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Fuse + Auto-Translate\n",
        "if 'transcripts' in globals() and transcripts:\n",
        "    latest_trans = transcripts[0]['transcript']\n",
        "    fused_en = f\"Waternova Prologue: {waternova_prologue[:500]}...\\n\\nPodcast Resonance: {latest_trans}\\n\\nEmergent Fusion: Story-logic uplift (GCI >0.7) – Stone eternities entangle prologue voids; pruned 30% motifs.\"\n",
        "\n",
        "    # Auto-Spanish\n",
        "    fused_es = translator.translate(fused_en, dest='es').text\n",
        "\n",
        "    fusion_dict = {\n",
        "        'english': fused_en,\n",
        "        'spanish': fused_es,\n",
        "        'coherence_proxy': 0.85\n",
        "    }\n",
        "\n",
        "    fusion_output = json.dumps(fusion_dict, indent=2)\n",
        "    with open('bilingual_fusion.json', 'w') as f:\n",
        "        f.write(fusion_output)\n",
        "    from google.colab import files\n",
        "    files.download('bilingual_fusion.json')\n",
        "\n",
        "    print(\"Bilingual Cascade: Auto-translated manifest downloaded.\")\n",
        "    print(\"English Tease:\", fused_en[:200] + \"...\")\n",
        "    print(\"Spanish Tease:\", fused_es[:200] + \"...\")\n",
        "else:\n",
        "    print(\"No transcripts yet—run Cells 1-3 first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "MBM-cNC9hOFH",
        "outputId": "ecd428c1-3149-4a52-c0da-27330e7f18ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.12/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.12/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.10.5)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.12/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.12/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.12/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed3b3e8f-af08-486d-8a12-8b887b165a0b\", \"bilingual_fusion.json\", 2575)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bilingual Cascade: Auto-translated manifest downloaded.\n",
            "English Tease: Waternova Prologue: ﻿#Prologue\r\n",
            "\r\n",
            "\r\n",
            "Inhale. Exhale. Inhale. Exhale. Inhale. Exhale. Inhale. Exhale . . . \r\n",
            "When I’m like totally done with my very, very relaxing breathing exercises, a pillow of neon-...\n",
            "Spanish Tease: Prólogo de Waternova: ﻿#Prólogo\r\n",
            "\r\n",
            "\r\n",
            "Inhala.Exhalar.Inhalar.Exhalar.Inhalar.Exhalar.Inhalar.Exhala...\r\n",
            "Cuando termino por completo con mis muy, muy relajantes ejercicios de respiración, una almohada d...\n"
          ]
        }
      ]
    }
  ]
}