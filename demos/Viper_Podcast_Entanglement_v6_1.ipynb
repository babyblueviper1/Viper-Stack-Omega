{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch feedparser requests\n",
        "\n",
        "import feedparser\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from datetime import datetime\n",
        "import os\n",
        "import glob\n",
        "from google.colab import files  # For downloads"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LuWbFNP4378j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKiGFzmn36aU"
      },
      "outputs": [],
      "source": [
        "# Dual Feed: BBV Podcast + Waternova Audiobook (3 eps each for low entropy)\n",
        "FEED_URLS = {\n",
        "    'bbv_podcast': \"https://api.substack.com/feed/podcast/623622/s/13426.rss\",\n",
        "    'waternova_audiobook': \"https://api.substack.com/feed/podcast/623622/s/10267.rss\"  # Your audiobook feed\n",
        "}\n",
        "PREVIEW_SECS = 60  # Skirt paywalls; bump for full\n",
        "\n",
        "episodes = []\n",
        "for feed_name, url in FEED_URLS.items():\n",
        "    print(f\"ðŸœ‚ Pulling {feed_name} feed...\")\n",
        "    feed = feedparser.parse(url)\n",
        "    for entry in feed.entries[:3]:  # 3 for low entropy\n",
        "        title = entry.title\n",
        "        date = entry.published if 'published' in entry else str(datetime.now())\n",
        "        desc = entry.summary[:100] + \"...\" if entry.summary else \"\"\n",
        "        audio_url = next((enc.href for enc in entry.enclosures if enc.type == 'audio/mpeg'), None)\n",
        "\n",
        "        if audio_url:\n",
        "            temp_file = f\"temp_{feed_name}_{title[:20].replace(' ', '_')}.mp3\"\n",
        "            resp = requests.get(audio_url, stream=True)\n",
        "            if resp.status_code == 200:\n",
        "                with open(temp_file, 'wb') as f:\n",
        "                    chunk_size = 8192\n",
        "                    total_bytes = 0\n",
        "                    for chunk in resp.iter_content(chunk_size=chunk_size):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                            total_bytes += len(chunk)\n",
        "                            if total_bytes > PREVIEW_SECS * 16000:\n",
        "                                break\n",
        "                print(f\"Downloaded {feed_name} preview: {title}\")\n",
        "            else:\n",
        "                print(f\"Skip {feed_name}: {title} (HTTP {resp.status_code})\")\n",
        "                continue\n",
        "\n",
        "        episodes.append({'title': title, 'date': date, 'desc': desc, 'temp_file': temp_file, 'feed': feed_name})\n",
        "\n",
        "print(f\"Queued {len(episodes)} episodes from {len(FEED_URLS)} feeds for transcription.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Whisper (base: fast, accurate enough for previews)\n",
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
        "\n",
        "transcripts = []\n",
        "for ep in episodes:\n",
        "    if 'temp_file' in ep and os.path.exists(ep['temp_file']):\n",
        "        # Enable long-form for >30s clips (timestamps auto-ignored for text)\n",
        "        transcript = transcriber(ep['temp_file'], return_timestamps=True)['text']\n",
        "\n",
        "        # Simple Prune: Filter short words, cap length (GCI proxy: >0.7 words/util)\n",
        "        words = [w for w in transcript.split() if len(w) > 3]\n",
        "        pruned = ' '.join(words[:250])  # Entropy cap; tie to S(Ï) via numpy later\n",
        "\n",
        "        ep['transcript'] = pruned\n",
        "        ep['coherence_proxy'] = min(1.0, max(0.0, len(words) / 250))  # Quick >0.7 check (capped 0-1)\n",
        "\n",
        "        # VOW Flag\n",
        "        if ep['coherence_proxy'] < 0.7:\n",
        "            print(f\"Low resonance: {ep['title']} â†’ recalibrate_equilibria\")\n",
        "        else:\n",
        "            print(f\"Pruned: {ep['title']} ({len(words)} words)\")\n",
        "\n",
        "        # Clean temp\n",
        "        os.remove(ep['temp_file'])\n",
        "\n",
        "    transcripts.append(ep)\n",
        "\n",
        "# Output as JSON (downloadable)\n",
        "import json\n",
        "output = json.dumps(transcripts, indent=2, default=str)\n",
        "with open('podcast_transcripts.json', 'w') as f:\n",
        "    f.write(output)\n",
        "files.download('podcast_transcripts.json')  # Auto-downloads to your machine\n",
        "\n",
        "print(\"Fusion-ready: transcripts.json downloaded. Feed to diversity_entropy_v6.py!\")"
      ],
      "metadata": {
        "id": "IX80TH6q4EZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Auto-discover .txt files via GitHub API (public repo)\n",
        "api_url = \"https://api.github.com/repos/babyblueviper1/Viper-Stack-Omega/contents/narratives/Waternova/chapters\"\n",
        "resp = requests.get(api_url)\n",
        "if resp.status_code == 200:\n",
        "    files_list = [item['name'] for item in resp.json() if item['name'].endswith('.txt')]\n",
        "    chapter_files = sorted(files_list)  # Sorts numerically if prefixed\n",
        "    print(\"Detected chapters:\", chapter_files)  # e.g., ['00-Prologue.txt', '01-Chapter One.txt', ...]\n",
        "else:\n",
        "    print(f\"API Miss: {resp.status_code}â€”check repo path/public status\")\n",
        "    chapter_files = [\"00-Prologue.txt\"]  # Fallback"
      ],
      "metadata": {
        "id": "fPxu74k97FJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from google.colab import files  # Explicit for download\n",
        "\n",
        "# Corrected Repo base\n",
        "REPO_RAW_BASE = \"https://raw.githubusercontent.com/babyblueviper1/Viper-Stack-Omega/main/narratives/Waternova/chapters\"\n",
        "\n",
        "# Use auto-detected list from previous cell (or hardcode if API misses)\n",
        "# chapter_files = ['00-Prologue.txt', '01-Awakening.txt']  # Uncomment if needed\n",
        "\n",
        "# Auto-fetch function\n",
        "def load_chapter(file_name):\n",
        "    url = f\"{REPO_RAW_BASE}/{file_name}\"\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code == 200:\n",
        "        return resp.text.strip()\n",
        "    else:\n",
        "        print(f\"Missed: {file_name} (HTTP {resp.status_code}â€”check name/path)\")\n",
        "        return \"\"\n",
        "\n",
        "# Load all\n",
        "waternova_chapters = {f: load_chapter(f) for f in chapter_files}\n",
        "waternova_prologue = waternova_chapters.get(\"00-Prologue.txt\", \"Fallback: Paste if fetch fails.\")\n",
        "\n",
        "# Bilingual Setup\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "# Fuse + Auto-Translate\n",
        "if 'transcripts' in globals() and transcripts:\n",
        "    latest_trans = transcripts[0]['transcript']\n",
        "    fused_en = f\"Waternova Prologue: {waternova_prologue[:400]}...\\n\\nPodcast Resonance: {latest_trans}\\n\\nEmergent Fusion: Story-logic uplift (GCI >0.7) â€“ Stone eternities entangle prologue voids; pruned 30% motifs.\"\n",
        "\n",
        "    # Auto-Spanish\n",
        "    fused_es = translator.translate(fused_en, dest='es').text\n",
        "\n",
        "    fusion_dict = {\n",
        "        'english': fused_en,\n",
        "        'spanish': fused_es,\n",
        "        'coherence_proxy': 0.85\n",
        "    }\n",
        "\n",
        "    fusion_output = json.dumps(fusion_dict, indent=2, ensure_ascii=False)\n",
        "    with open('bilingual_fusion.json', 'w') as f:\n",
        "        f.write(fusion_output)\n",
        "    files.download('bilingual_fusion.json')\n",
        "\n",
        "    print(\"Bilingual Cascade: Auto-translated manifest downloaded.\")\n",
        "    print(\"English Tease:\", fused_en[:200] + \"...\")\n",
        "    print(\"Spanish Tease:\", fused_es[:200] + \"...\")\n",
        "else:\n",
        "    print(\"No transcripts yetâ€”run Cells 1-3 first.\")"
      ],
      "metadata": {
        "id": "_qYnMmX1CdjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}